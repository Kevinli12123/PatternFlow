# OASIS Brain image generation using StyleGAN

## Algorithm description

![res_block](https://github.com/Kevinli12123/PatternFlow/blob/s4574204-boli-styleGAN2/picture/v2-e27f75092944b85be833fd93f53dd35f_b.jpeg)

  &emsp;The images generated by GAN have developed rapidly in terms of resolution and quality, but before that, a lot of research work still regarded the generator as a black box, that is, lack of understanding of the image generation process of the generator, such as image diversity How to control the random features in, the nature of the latent space is also poorly understood.<br>
  &emsp;Inspired by style transfer, StyleGAN redesigned the generator network structure and tried to control the image generation process: the generator starts from the learned constant input, and adjusts the image "style" of each convolutional layer based on the latent code, thereby directly controlling Image features; in addition, combined with noise directly injected into the network, random attributes (such as freckles, hair) in the generated image can be changed. StyleGAN can achieve unsupervised attribute separation to a certain extent, and perform some style mixing or interpolation operations. 



## Brain image generation problem
This is about creating the similar pictures of OASIS brain. It using the random latent factors to fit the distribution of pixels of the real image data and try to use the trained function to create the clear image.

## Train parameters and procedure
The used activation is leaky Relu with alpha = .01.
The used optimizer is Adam and I used learning rate of .0005 
The project used  similarity loss to train their model, but I couldnâ€™t implement it, so I used Categorical cross entropy, and used Dice Similarity Coefficient as a metric to monitor training. 
I used multiples of 16 filters at each level of the network exactly as specified by the paper.  
I trained the model for 200 ephocs.

The dataset was already split into training, validation and test data sets. Validation dataset is useful during training to monitor training for overfitting and I used test dataset to assess model generalization capability on a set not seen during training. 
## Dependencies and data pre-processing 
The test script download , unzip the dataset images. The methods that load and process dataset take the directory path were the images were downloaded as a parameter. An update to these file paths might be required for the algorithm to run. 

Training data was normalized by subtracting mean and dividing by standard deviation and then normalizing the pixel values between 0-1. I noticed that normalizing the data this way results in a more stable training vs dividing by 255.
The label images as well need to be pre-processed and converted to one hot encoding representation. 



## Output 
The below results show the ssim score is 0.625's graph.

![res_block](https://github.com/Kevinli12123/PatternFlow/blob/s4574204-boli-styleGAN2/picture/generated_plot_e008.png)


## model summery


